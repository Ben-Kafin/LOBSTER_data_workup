# -*- coding: utf-8 -*-
"""
Created on Tue Mar 18 18:41:08 2025

@author: Benjamin Kafin
"""
from __future__ import annotations

import collections
import fnmatch
import itertools
import os
import re
import warnings
from collections import defaultdict
from typing import TYPE_CHECKING, cast

import numpy as np
from monty.dev import deprecated
from monty.io import zopen
from monty.json import MSONable

from pymatgen.core.structure import Structure
from pymatgen.electronic_structure.bandstructure import LobsterBandStructureSymmLine
from pymatgen.electronic_structure.core import Orbital, Spin
from pymatgen.electronic_structure.dos import Dos, LobsterCompleteDos
from pymatgen.io.vasp.inputs import Kpoints
from pymatgen.io.vasp.outputs import Vasprun, VolumetricData
from pymatgen.util.due import Doi, due
from pymatgen.util.typing import PathLike

if TYPE_CHECKING:
    from typing import Any, ClassVar, Literal

    from numpy.typing import NDArray

    from pymatgen.core.structure import IStructure
    from pymatgen.electronic_structure.cohp import IcohpCollection
    from pymatgen.util.typing import Tuple3Ints, Vector3D

import re
import numpy as np
from monty.io import zopen
from pymatgen.electronic_structure.core import Orbital, Spin
from pymatgen.util.typing import PathLike
from pymatgen.core.structure import Structure
from pymatgen.electronic_structure.dos import Dos, LobsterCompleteDos
from numpy.typing import NDArray
from collections import defaultdict
from typing import Any


class Cohpcar:
    """Read COXXCAR.lobster/COXXCAR.LCFO.lobster files generated by LOBSTER with LCFO fragments support."""

    def __init__(
        self,
        are_coops: bool = False,
        are_cobis: bool = False,
        are_multi_center_cobis: bool = False,
        is_lcfo: bool = False,
        filename: PathLike | None = None,
        lcfo_fragments_path: PathLike | None = None,  # New parameter for LCFO fragments
    ) -> None:
        """
        Args:
            are_coops (bool): Whether the file includes COOPs (True) or COHPs (False).
            are_cobis (bool): Whether the file is COBIs (True) or COHPs (False).
            are_multi_center_cobis (bool): Whether the file includes multi-center COBIs (True).
            is_lcfo (bool): Whether the COXXCAR file is from LCFO analysis.
            filename (PathLike): The COHPCAR file. If it is None, the default
                file name will be chosen, depending on the value of are_coops.
            lcfo_fragments_path (PathLike): Path to the LCFO_fragments file to map fragments to atoms/groups.
        """
        # Ensure only one file type is being processed
        if (
            (are_coops and are_cobis)
            or (are_coops and are_multi_center_cobis)
            or (are_cobis and are_multi_center_cobis)
        ):
            raise ValueError("You cannot have info about COOPs, COBIs and/or multi-center COBIS in the same file.")

        self.are_coops = are_coops
        self.are_cobis = are_cobis
        self.are_multi_center_cobis = are_multi_center_cobis
        self.is_lcfo = is_lcfo
        self._filename = filename

        # Default filename handling
        if self._filename is None:
            if are_coops:
                self._filename = "COOPCAR.lobster"
            elif are_cobis or are_multi_center_cobis:
                self._filename = "COBICAR.lobster"
            else:
                self._filename = "COHPCAR.lobster"

        # Parse LCFO fragments if a path is provided
        self.lcfo_fragments = None
        if is_lcfo and lcfo_fragments_path:
            self.lcfo_fragments = self._parse_lcfo_fragments(lcfo_fragments_path)

        # Read and process the COHPCAR file
        with zopen(self._filename, mode="rt", encoding="utf-8") as file:
            lines = file.read().split("\n")

        parameters = lines[1].split()
        num_bonds = int(parameters[0]) if self.are_multi_center_cobis else int(parameters[0]) - 1
        self.efermi = float(parameters[-1])
        self.is_spin_polarized = int(parameters[1]) == 2
        spins = [Spin.up, Spin.down] if self.is_spin_polarized else [Spin.up]

        # Prepare COHP data
        cohp_data: dict[str, dict[str, Any]] = {}
        if not self.are_multi_center_cobis:
            data = np.array([np.array(line.split(), dtype=float) for line in lines[num_bonds + 3 :]]).transpose()
            cohp_data = {
                "average": {
                    "COHP": {spin: data[1 + 2 * s * (num_bonds + 1)] for s, spin in enumerate(spins)},
                    "ICOHP": {spin: data[2 + 2 * s * (num_bonds + 1)] for s, spin in enumerate(spins)},
                }
            }

        # Initialize COHP and orbital-resolved COHP structures
        self.energies = data[0]
        orb_cohp: dict[str, Any] = {}
        bond_num = 0
        bond_data = {}

        for bond in range(num_bonds):
            bond_data = self._get_bond_data(
                lines[3 + bond],
                is_lcfo=self.is_lcfo,
                lcfo_fragments=self.lcfo_fragments,
            )
            label = str(bond_num)
            orbs = bond_data["orbitals"]

            cohp = {spin: data[2 * (bond + s * (num_bonds + 1)) + 3] for s, spin in enumerate(spins)}
            icohp = {spin: data[2 * (bond + s * (num_bonds + 1)) + 4] for s, spin in enumerate(spins)}

            if orbs is None:
                bond_num += 1
                label = str(bond_num)
                cohp_data[label] = {
                    "COHP": cohp,
                    "ICOHP": icohp,
                    "length": bond_data["length"],
                    "sites": bond_data["sites"],
                }
            elif label in orb_cohp:
                orb_cohp[label] |= {
                    bond_data["orb_label"]: {
                        "COHP": cohp,
                        "ICOHP": icohp,
                        "orbitals": orbs,
                        "length": bond_data["length"],
                        "sites": bond_data["sites"],
                    }
                }
            else:
                bond_num += 1
                label = str(bond_num)
                orb_cohp[label] = {
                    bond_data["orb_label"]: {
                        "COHP": cohp,
                        "ICOHP": icohp,
                        "orbitals": orbs,
                        "length": bond_data["length"],
                        "sites": bond_data["sites"],
                    }
                }

        self.orb_res_cohp = orb_cohp or None
        self.cohp_data = cohp_data

    @staticmethod
    def _get_bond_data(line, is_lcfo, lcfo_fragments=None):
        """
        Extract bond label, site indices, and length, mapping LCFO fragment names if needed.
        """
        line_new = line.rsplit("(", 1)
        length = float(line_new[-1][:-1])
        sites = line_new[0].replace("->", ":").split(":")[1:3]

        # Map LCFO fragment names to original atom names if LCFO fragments are provided
        if lcfo_fragments:
            sites = [lcfo_fragments.get(site.split("[")[0], site) for site in sites]

        if "[" in sites[0]:
            orbs = [re.findall(r"\[(.*)\]", site)[0] for site in sites]
            orb_label = "-".join(orbs)
            orbitals = orbs
        else:
            orbitals = None
            orb_label = None

        return {
            "length": length,
            "sites": sites,
            "orbitals": orbitals,
            "orb_label": orb_label,
        }

    @staticmethod
    def _parse_lcfo_fragments(fragment_file_path):
        """
        Parse LCFO fragments to map fragment names to atom names or groups.
        """
        fragments = {}
        current_fragment = None

        with open(fragment_file_path, "r") as f:
            for line in f:
                line = line.strip()
                if line.startswith("Atoms forming fragment"):
                    current_fragment = line.split()[3]
                    fragments[current_fragment] = []
                elif current_fragment and line:
                    fragments[current_fragment].append(line.split()[0])

        return fragments


from pathlib import Path
import numpy as np
from collections import defaultdict
from pymatgen.electronic_structure.dos import Dos
from pymatgen.electronic_structure.core import Spin
from pymatgen.core.structure import Structure

class DOSCAR_LCFO:
    """
    Parses DOSCAR.LCFO files for TDOS, pMODOS, and optionally LDOS, while following Pymatgen's LobsterDoscar logic.
    Includes MO mapping from the MO diagram and fragment-to-structure mapping.
    """
    def __init__(self, doscar: Path, lcfo_fragments_path: Path, mo_diagram: dict, structure_file: Path = None):
        """
        Args:
            doscar (Path): Path to the DOSCAR.LCFO file.
            lcfo_fragments_path (Path): Path to the LCFO_Fragments.lobster file.
            mo_diagram (dict): MO diagram mapping molecular orbital names to keys.
            structure_file (Path): Optional path to a structure file (e.g., POSCAR) for LDOS.
        """

        # Assign attributes
        self._doscar = doscar
        self._lcfo_fragments_path = lcfo_fragments_path
        self._mo_diagram = mo_diagram
        self._structure = Structure.from_file(structure_file) if structure_file else None
    
        # Attributes to store parsed data
        self._energies = None
        self._tdos = None
        self._pmodos = None
        self._ldos = {}  # Initialize LDOS as an empty dictionary
        self._is_spin_polarized = None
    
        # Log progress
        print(f"Parsing DOSCAR.LCFO from: {doscar}")
        print(f"Parsing LCFO_Fragments from: {lcfo_fragments_path}")
        if structure_file:
            print(f"Using structure file (POSCAR) from: {structure_file}")
    
        # Parse the files
        self._fragments = self._parse_lcfo_fragments()
        self._parse_doscar()

    def _parse_lcfo_fragments(self):
        """
        Parses the LCFO_Fragments.lobster file to extract fragment and orbital mappings.
        Returns:
            dict: A dictionary mapping fragment names to orbital names and atomic indices.
        """
        fragments = {}
        current_fragment = None

        with open(self._lcfo_fragments_path, "r") as file:
            for line in file:
                line = line.strip()
                if not line:
                    continue

                if line.startswith("Atoms forming fragment"):
                    current_fragment = line.split("on")[0].strip().replace("Atoms forming ", "")
                    fragments[current_fragment] = {"orbitals": [], "atoms": []}
                    continue

                if "_" in line and any(char.isdigit() for char in line):  # Parse atomic indices
                    atom_name = line.split()[0].strip()
                    atomic_index = int(atom_name.split("_")[1]) - 1  # Convert to 0-based index
                    fragments[current_fragment]["atoms"].append(atomic_index)
                    continue

                if ";" in line:  # Parse orbitals
                    parts = line.split(";")
                    fragment_name = parts[0].strip()
                    orbitals = parts[1].strip().split()
                    # Append molecular orbitals if the fragment is in the MO diagram
                    if fragment_name in self._mo_diagram:
                        detailed_orbitals = [
                            f"{fragment_name}_1_{orb}" for orb in orbitals
                        ]
                        fragments[fragment_name]["orbitals"] = detailed_orbitals
                    else:
                        fragments[fragment_name]["orbitals"] = orbitals

        return fragments

    def _parse_doscar(self):
        """
        Parses the DOSCAR.LCFO file to extract TDOS and pMODOS data.
        Renames 'Au' fragments dynamically based on their corresponding atom number from the POSCAR file.
        """
        with open(self._doscar, "r") as file:
            # Skip the first 5 lines (headers and metadata)
            for _ in range(5):
                file.readline()
    
            # Parse the 6th line for Fermi energy
            fermi_line = file.readline().strip()
            try:
                efermi = float(fermi_line.split()[3])  # Fermi energy is the 4th value
            except (IndexError, ValueError):
                raise ValueError("Could not parse Fermi energy from the 6th line of DOSCAR.LCFO.")
    
            # Initialize arrays for TDOS
            energies = []
            spin_up_densities = []
            spin_down_densities = []
    
            # Parse TDOS while skipping metadata lines
            while True:
                line = file.readline().strip()
                if ";" in line:  # Start of pMODOS metadata
                    break
                if not line or any(char.isalpha() for char in line.split()):  # Skip metadata lines
                    continue
                columns = [float(x) for x in line.split()]
                energies.append(columns[0])  # Energy column
                spin_up_densities.append(columns[1])  # Spin-up density
                if len(columns) > 2:  # Spin-down density (if spin-polarized)
                    spin_down_densities.append(columns[2])
    
            # Determine spin polarization
            self._is_spin_polarized = len(spin_down_densities) > 0
            tdensities = {Spin.up: np.array(spin_up_densities)}
            if self._is_spin_polarized:
                tdensities[Spin.down] = np.array(spin_down_densities)
    
            # Assign TDOS and energies
            self._tdos = Dos(efermi, np.array(energies), tdensities)
            self._energies = np.array(energies)
    
            # Parse fragments and orbitals sequentially for pMODOS
            pmodos = defaultdict(lambda: defaultdict(lambda: {Spin.up: [], Spin.down: []}))
            fragments = list(self._fragments.keys())  # Get fragments in sequential order
    
            fragment_index = 0  # Start with the first fragment
            while line:
                if ";" in line:  # Fragment and orbital metadata
                    # Split the metadata line by semicolons
                    metadata = line.split(";")
                    if len(metadata) < 3:
                        raise ValueError(f"Invalid metadata format: {line}")
    
                    fragment_name = metadata[1].strip()  # Fragment name comes after the first semicolon
                    orbital_section = metadata[2].strip()  # Orbital names are after the second semicolon
    
                    # Skip "X" and extract only actual orbital names
                    orbital_parts = orbital_section.split()
                    orbitals = [orb for orb in orbital_parts if orb != "X"]  # Exclude "X"
                    num_orbitals = len(orbitals)  # Dynamically determine number of orbitals
    
                    # Map fragment to structure sequentially and rename fragment if it's 'Au'
                    fragment_atoms = self._fragments.get(fragments[fragment_index], {}).get("atoms", [])
                    if fragment_name == 'Au':
                        fragment_name = f"Au_{fragment_atoms[0]}"  # Rename fragment using atom number
                    print(f"Processed fragment '{fragment_name}' with atoms: {fragment_atoms} and orbitals: {orbitals}")
                    fragment_index += 1  # Move to the next fragment in sequential order
                    line = file.readline()  # Move to numeric rows
                    continue
    
                # Parse numeric rows for pMODOS densities
                rows_read = 0  # Track the number of rows processed
                while line and (";" not in line or fragment_index == len(fragments)):  # Keep reading numeric rows
                    columns = [float(x) for x in line.split()]
                    expected_columns = 1 + 2 * num_orbitals  # Calculate expected columns dynamically
    
                    if len(columns) != expected_columns:  # Validate column count
                        raise ValueError(f"Column mismatch for fragment '{fragment_name}'. "
                                         f"Expected {expected_columns} columns, but got {len(columns)}.")
    
                    energy = columns[0]
                    for i, orbital in enumerate(orbitals):
                        spin_up_col = (i * 2) + 1
                        spin_down_col = (i * 2) + 2
                        pmodos[fragment_name][orbital][Spin.up].append(columns[spin_up_col])
                        if self._is_spin_polarized:
                            pmodos[fragment_name][orbital][Spin.down].append(columns[spin_down_col])
                    rows_read += 1
    
                    # Read the next line or stop processing
                    line = file.readline().strip()
    
                    # If the end of file is reached, terminate numeric row processing
                    if not line:
                        print(f"End of file reached for fragment '{fragment_name}'")
                        break
    
                # Debug output for each pMODOS row
                print(f"Processed {rows_read} rows for fragment '{fragment_name}'")
    
            # Validate energy-density alignment for pMODOS
            for fragment, orbital_data in pmodos.items():
                for orbital, spin_data in orbital_data.items():
                    if len(spin_data[Spin.up]) != len(self._energies):
                        raise ValueError(f"Mismatch for fragment '{fragment}', orbital '{orbital}': "
                                         f"{len(spin_data[Spin.up])} densities vs {len(self._energies)} energies.")
                    if self._is_spin_polarized and len(spin_data[Spin.down]) != len(self._energies):
                        raise ValueError(f"Spin Down mismatch for fragment '{fragment}', orbital '{orbital}': "
                                         f"{len(spin_data[Spin.down])} densities vs {len(self._energies)} energies.")
    
            # Assign parsed pMODOS
            self._pmodos = pmodos
        
        
    @property
    def tdos(self) -> Dos:
        """Returns the Total Density of States (TDOS)."""
        return self._tdos

    @property
    def pmodos(self) -> dict:
        """Returns the Projected Molecular Orbital DOS (pMODOS)."""
        return self._pmodos

    @property
    def energies(self) -> np.ndarray:
        """Returns the energies associated with the DOS."""
        return self._energies

    @property
    def is_spin_polarized(self) -> bool:
        """Returns whether the system is spin-polarized."""
        return self._is_spin_polarized


# Enhanced Icohplist class with full support for LCFO and orbital-wise files
class Icohplist(MSONable):
    """Read ICOXXLIST/ICOXXLIST.LCFO.lobster files generated by LOBSTER.

    Extended to handle standard, LCFO, orbital-wise, and LCFO + orbital-wise formats.
    """
    def __init__(
        self,
        is_lcfo: bool = False,
        are_coops: bool = False,
        are_cobis: bool = False,
        filename: PathLike | None = None,
        is_spin_polarized: bool = False,
        orbitalwise: bool = False,
        icohpcollection: IcohpCollection | None = None,
    ) -> None:
        """
        Initialize the Icohplist class.

        Args:
            is_lcfo (bool): Whether the ICOHPLIST file is from LCFO analysis.
            are_coops (bool): Whether the file includes COOPs (True) or COHPs (False).
            are_cobis (bool): Whether the file is COBIs (True) or COHPs (False).
            filename (PathLike): Path to the ICOHPLIST file.
            is_spin_polarized (bool): Whether the calculation is spin polarized.
            orbitalwise (bool): Whether the calculation is orbital-wise.
            icohpcollection (IcohpCollection): IcohpCollection object for compatibility.
        """
        super().__init__()
        self._filename = filename
        self.is_lcfo = is_lcfo
        self.is_spin_polarized = is_spin_polarized
        self.orbitalwise = orbitalwise
        self.are_coops = are_coops
        self.are_cobis = are_cobis
        self._icohpcollection = icohpcollection
        self.icohplist = {}  # Parsed data stored here
        self._parse_file()  # Parse the file during initialization

    def _parse_file(self):
        """Parse the ICOHPLIST file and detect its format."""
        with zopen(self._filename, mode="rt", encoding="utf-8") as file:
            all_lines = file.readlines()

        # Detect format
        self._detect_format(all_lines)

        # Parse based on format
        if self.is_lcfo and self.orbitalwise:
            self._parse_lcfo_orbitalwise(all_lines)
        elif self.is_lcfo:
            self._parse_lcfo(all_lines)
        elif self.orbitalwise:
            self._parse_orbitalwise(all_lines)
        else:
            self._parse_standard(all_lines)

    def _detect_format(self, lines):
        """Detect the file format."""
        header = lines[0].strip().split()
        # Check for LCFO-specific columns
        self.is_lcfo = "fragmentAlpha" in header and "fragmentBeta" in header
        # Check for orbital-specific data
        self.orbitalwise = any("_" in col for col in lines[1].strip().split())
        # Determine spin polarization
        self.is_spin_polarized = any("spin 2" in line for line in lines[:10])

    def _parse_standard(self, lines):
        """Parse non-LCFO and non-orbital-wise ICOHP files dynamically for one or two spins."""
        # Skip the first two header lines
        data_lines = lines[2:]
    
        for line in data_lines:
            tokens = line.strip().split()
    
            # Ensure line has enough tokens to process
            if len(tokens) < 8:  # At least 8 tokens needed for minimal valid data
                print(f"Skipping malformed line: {line.strip()}")
                continue
    
            try:
                bond_index = tokens[0]  # COHP#
                atom1 = tokens[1]       # atomMU
                atom2 = tokens[2]       # atomNU
                bond_length = float(tokens[3])  # distance
    
                # Skip translation vectors (tokens[4], tokens[5], tokens[6])
                translation = tokens[4:7]  # Save translation vectors for later use, if needed
    
                # Determine if the file includes one or two spins
                if len(tokens) == 8:  # Only one spin value present
                    icohp_spin1 = float(tokens[7])  # ICOHP for spin 1
                    icohp_spin2 = None  # No spin 2 value
                elif len(tokens) == 9:  # Two spin values present
                    icohp_spin1 = float(tokens[7])  # ICOHP for spin 1
                    icohp_spin2 = float(tokens[8])  # ICOHP for spin 2
                else:
                    print(f"Unexpected token count in line: {line.strip()}")
                    continue
    
                # Create the ICOHP entry
                icohp_entry = {
                    "atomMU": atom1,
                    "atomNU": atom2,
                    "length": bond_length,
                    "translation": translation,  # Optional; can be omitted if not needed
                    "icohp": {"spin1": icohp_spin1, "spin2": icohp_spin2},
                }
                self.icohplist[bond_index] = icohp_entry
                print(f"Parsed entry {bond_index}: {icohp_entry}")
    
            except ValueError as e:
                print(f"Error parsing line: {line.strip()} - {e}")
                continue

    def _parse_orbitalwise(self, lines, top_contributors=3):
        """Parse orbital-wise ICOHP files dynamically."""
        current_bond = None
        orbital_contributions = {}
    
        # Skip the first two header lines
        data_lines = lines[2:]
    
        for line in data_lines:
            tokens = line.strip().split()
    
            # Ensure line has enough tokens to process
            if len(tokens) < 8:  # At least 8 tokens needed for minimal valid data
                print(f"Skipping malformed line: {line.strip()}")
                continue
    
            try:
                # Detect bond index
                if tokens[0].startswith("COHP#"):
                    current_bond = tokens[0].split("#")[1]
                    continue
    
                orbital1 = tokens[1]
                orbital2 = tokens[2]
                bond_length = float(tokens[3])
                icohp_spin1 = float(tokens[7])
                icohp_spin2 = float(tokens[8]) if self.is_spin_polarized else None
    
                # If this is the first line for the bond index, treat as atomic ICOHP
                if current_bond not in self.icohplist:
                    # Save atomic ICOHP entry
                    atomic_entry = {
                        "atomMU": orbital1,
                        "atomNU": orbital2,
                        "length": bond_length,
                        "translation": tokens[4:7],
                        "icohp": {"spin1": icohp_spin1, "spin2": icohp_spin2},
                        "orbital_contributions": [],  # Placeholder for orbital contributions
                    }
                    self.icohplist[current_bond] = atomic_entry
                else:
                    # Save individual orbital interaction under current bond index
                    orbital_entry = {
                        "orbitalMU": orbital1,
                        "orbitalNU": orbital2,
                        "length": bond_length,
                        "translation": tokens[4:7],
                        "icohp": {"spin1": icohp_spin1, "spin2": icohp_spin2},
                    }
                    if current_bond not in orbital_contributions:
                        orbital_contributions[current_bond] = []
                    orbital_contributions[current_bond].append(orbital_entry)
            except ValueError as e:
                print(f"Error parsing line: {line.strip()} - {e}")
                continue
    
        # Calculate top orbital contributors for each bond index
        for bond_index, orbitals in orbital_contributions.items():
            if bond_index not in self.icohplist:
                continue  # Skip bonds without atomic ICOHP entries
    
            # Retrieve total atomic ICOHP
            total_atomic_icohp = self.icohplist[bond_index]["icohp"]["spin1"]
    
            # Calculate closeness to total atomic ICOHP
            contributions = [
                {
                    "interaction": f"{entry['orbitalMU']} - {entry['orbitalNU']}",
                    "icohp": entry["icohp"]["spin1"],
                    "difference": abs(entry["icohp"]["spin1"] - total_atomic_icohp),
                }
                for entry in orbitals
            ]
    
            # Sort by closeness to the atomic ICOHP
            contributions = sorted(contributions, key=lambda x: x["difference"])
    
            # Keep only the top contributors
            top_contributions = contributions[:top_contributors]
    
            # Save top contributions in atomic entry
            self.icohplist[bond_index]["orbital_contributions"] = top_contributions
    
            print(f"Processed bond {bond_index} with top contributions: {top_contributions}")


    def _parse_lcfo(self, lines):
        """Parse LCFO ICOHP files dynamically for fragments, skipping translation vectors."""
        # Skip the first two header lines, consistent with standard format
        data_lines = lines[2:]
    
        for line in data_lines:
            tokens = line.strip().split()
    
            # Ensure line has enough tokens to process
            if len(tokens) < 8:  # At least 8 tokens needed for minimal valid data
                print(f"Skipping malformed line: {line.strip()}")
                continue
    
            try:
                bond_index = tokens[0]  # COHP#
                fragment1 = tokens[1]  # Fragment Alpha
                fragment2 = tokens[2]  # Fragment Beta
                bond_length = float(tokens[3])  # Distance
    
                # Skip translation vectors (tokens[4], tokens[5], tokens[6])
                translation = tokens[4:7]  # Save translation vectors for context or discard
    
                # Determine if the file includes one or two spins
                if len(tokens) == 8:  # Only one spin value present
                    icohp_spin1 = float(tokens[7])  # ICOHP for spin 1
                    icohp_spin2 = None  # No spin 2 value
                elif len(tokens) == 9:  # Two spin values present
                    icohp_spin1 = float(tokens[7])  # ICOHP for spin 1
                    icohp_spin2 = float(tokens[8])  # ICOHP for spin 2
                else:
                    print(f"Unexpected token count in line: {line.strip()}")
                    continue
    
                # Create the ICOHP entry
                icohp_entry = {
                    "fragmentAlpha": fragment1,
                    "fragmentBeta": fragment2,
                    "length": bond_length,
                    "translation": translation,  # Optional; can be omitted if not needed
                    "icohp": {"spin1": icohp_spin1, "spin2": icohp_spin2},
                }
                self.icohplist[bond_index] = icohp_entry
                print(f"Parsed entry {bond_index}: {icohp_entry}")
    
            except ValueError as e:
                print(f"Error parsing line: {line.strip()} - {e}")
                continue




    def _parse_lcfo_orbitalwise(self, lines):
        """Parse LCFO + orbital-wise ICOHP files."""
        current_bond = None
        for line in lines[1:]:
            tokens = line.strip().split()
    
            # Skip invalid or malformed lines
            if len(tokens) < 6 or not tokens[3].replace(".", "", 1).isdigit():
                continue
    
            if tokens[0].startswith("COHP#"):
                current_bond = tokens[0].split("#")[1]
                continue
    
            fragment1 = tokens[1]
            orbital2 = tokens[2]
            bond_length = float(tokens[3])
            icohp_spin1 = float(tokens[4])  # Spin 1 value
            icohp_spin2 = float(tokens[5]) if self.is_spin_polarized else None  # Spin 2 value if polarized
            icohp_entry = {
                "fragmentAlpha": fragment1,
                "orbitalBeta": orbital2,
                "length": bond_length,
                "icohp": {"spin1": icohp_spin1, "spin2": icohp_spin2},
            }
            if current_bond not in self.icohplist:
                self.icohplist[current_bond] = {"fragment_orbital_interactions": []}
            self.icohplist[current_bond]["fragment_orbital_interactions"].append(icohp_entry)

